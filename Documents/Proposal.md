# <p align="center"> Speech Emotion Recognition (SER)</p>

- Author: Pranay manikanta Narava
- Prepared for UMBC Data Science Master Degree Capstone by Dr Chaojie (Jay) Wang
- GitHub: https://github.com/NPranaya7?tab=repositories 
- LinkedIn: https://www.linkedin.com/in/pranayamanikanta07/ 
- Link to your PowerPoint presentation file
- Link to your  YouTube video 
    
## 1. Background

- What is it about?    
I am excited to explore the fascinating topic of Speech Emotions Recognition. This field involves recognizing human emotions and affective states through speech patterns. It is based on the understanding that our voices often convey our underlying emotions through changes in tone, pitch, and other auditory elements. This phenomenon is not exclusive to humans, as animals like dogs and horses can also comprehend human emotions through our speech patterns. By delving into this subject, we can better understand the intricate nature of human communication and the interplay between our emotions and vocal expressions.

- Why does it matter?    
The significance of emotions in human life cannot be overstated, as they play a pivotal role in facilitating effective communication. Therefore, it would be highly beneficial to create a machine-learning model that can analyze speech and discern an individual's emotional state accurately. Such technology could have numerous practical applications, making it a valuable asset to society.

- Research questions?
    - How accurately can we detect emotions and sentiments from voice recordings?
    - What are the cross-cultural differences in the perception of emotion in audio data?
    - Can emotion analysis from audio data be used in marketing or customer feedback analysis?
    - How can audio data be used in forensic investigations, such as voice identification, and speaker emotion state recognition?

## 2. Data 

- Data sources: https://zenodo.org/record/1188976
- Data size: 590.35 MB
- Data shape: 1440 (.wav) Audio files
- **Filename identified as per the official RAVDESS website**
  **Example Filename:  03-01-01-01-01-01-01.wav**
  - **Modality** (01 = full-AV, 02 = video-only, 03 = audio-only).
  - **Vocal channel** (01 = speech, 02 = song).
  - **Emotion** (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).
  - **Emotional intensity** (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.
  - **Statement** (01 = "Kids are talking by the door", 02 = "Dogs are sitting by the door").
  - **Repetition** (01 = 1st repetition, 02 = 2nd repetition).
  - **Actor** (01 to 24. Odd-numbered actors are male, even-numbered actors are female).

- Which variable/column will be your target/label in your ML model?    
  The **"Emotion"** column is the Target variable
  

## 3. Exploratory Data Analysis (EDA)



## 4. Model Training 



## 5. Application of the Trained Models



## 6. Conclusion


## 7. References 
